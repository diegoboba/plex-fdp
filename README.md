# Plex ETL Project

ETL pipeline para replicar bases de datos MySQL (Plex y Quantio) a BigQuery usando Google Cloud Platform.

## ğŸ—ï¸ Arquitectura

```
MySQL (Plex) â”€â”€â”
               â”œâ”€â”€ Python ETL â”€â”€ Google Storage â”€â”€ BigQuery â”€â”€ Vistas AnalÃ­ticas
MySQL (Quantio) â”˜                   â†‘
                         Cloud Functions (cada 12h)
```

## ğŸ“ Estructura del Proyecto

```
plex/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ database/           # Conexiones a MySQL
â”‚   â”‚   â”œâ”€â”€ connector.py
â”‚   â”‚   â””â”€â”€ secret_manager.py
â”‚   â”œâ”€â”€ etl/               # Procesos ETL
â”‚   â”‚   â””â”€â”€ extractor.py
â”‚   â”œâ”€â”€ cloud/             # Google Cloud services
â”‚   â”‚   â”œâ”€â”€ storage.py
â”‚   â”‚   â””â”€â”€ bigquery.py
â”‚   â”œâ”€â”€ utils/             # Utilidades
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ main.py            # Pipeline principal
â”œâ”€â”€ scripts/               # Scripts de setup
â”‚   â””â”€â”€ setup_secrets.py
â”œâ”€â”€ tests/                 # Tests
â”‚   â””â”€â”€ test_connections.py
â”œâ”€â”€ config/                # ConfiguraciÃ³n
â”‚   â””â”€â”€ database_config_complete.yaml
â”œâ”€â”€ deploy/                # Deployment
â”‚   â”œâ”€â”€ cloud_scheduler_setup.sh
â”‚   â””â”€â”€ terraform/
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”‚   â””â”€â”€ test_connections.ipynb
â””â”€â”€ docs/                  # DocumentaciÃ³n
```

## ğŸš€ Setup RÃ¡pido

### 1. Configurar entorno virtual
```bash
python3 -m venv plex
source plex/bin/activate
pip install -r requirements.txt
```

### 2. Configurar variables de entorno
```bash
export GCP_PROJECT_ID="plex-etl-project"
export GOOGLE_APPLICATION_CREDENTIALS="./etl-service-account-key.json"
```

### 3. Configurar secrets
```bash
python scripts/setup_secrets.py
```

### 4. Probar conexiones
```bash
python tests/test_connections.py
```

## ğŸ“Š Bases de Datos

### Plex (Principal)
- **factcabecera**: 9.2M facturas
- **factlineas**: 13.5M lÃ­neas de factura
- **stock**: 622K registros de inventario
- **medicamentos**: 772K productos

### Quantio (Complementaria)
- **productos**: 91K productos
- **stock**: 19K registros
- **stocklotes**: 156K lotes

## â° ProgramaciÃ³n

- **ETL incremental**: Cada 12 horas (12:00 AM y 12:00 PM)
- **ETL completo**: Domingos 2:00 AM
- **RetenciÃ³n**: 90 dÃ­as en Cloud Storage

## ğŸ’° Costos Estimados

- **~$29/mes** con ETL cada 12 horas
- **Optimizaciones**: Particionado, compresiÃ³n Parquet
- **Monitoreo**: Cloud Functions + BigQuery

## ğŸ”§ Uso

### Ejecutar ETL local
```bash
python src/main.py
```

### Ejecutar tests
```bash
python tests/test_connections.py
```

### Deploy a Cloud Functions
```bash
cd deploy/
./cloud_scheduler_setup.sh
```

## ğŸ“ˆ Vistas Creadas

1. **v_facturas_lineas**: Facturas consolidadas
2. **v_ventas_analysis**: AnÃ¡lisis de ventas
3. **v_reporte_bi_consolidado**: Reporte BI completo
4. **v_pedidos_lineas**: Pedidos consolidados

## ğŸ” Seguridad

- Credenciales en Google Secret Manager
- Service Account con permisos mÃ­nimos
- Conexiones SSL a MySQL
- Datos encriptados en Cloud Storage

## ğŸ“ Logs y Monitoreo

- Cloud Functions logs
- BigQuery job monitoring
- Storage operation logs
- Error alerting configurado