# ğŸ“‹ Plan de Desarrollo ETL FarmacÃ©utico - Estado Actual y PrÃ³ximos Pasos

**Fecha**: 2025-08-25  
**VersiÃ³n**: 2.0 - Post Limpieza  
**Estado**: âœ… **ETL Streaming Core Funcional** - Lista para OptimizaciÃ³n

## ğŸ¯ Resumen Ejecutivo

**El proyecto tiene un ETL streaming completamente funcional** que replica MySQL (Plex/Quantio) â†’ BigQuery usando chunks de 100k filas. La arquitectura central estÃ¡ sÃ³lida, pero necesita limpieza de cÃ³digo y optimizaciones especÃ­ficas.

### **âœ… Lo que Funciona (Mantener)**
- **Streaming ETL directo**: MySQL â†’ BigQuery sin Cloud Storage
- **86 relaciones FK** mapeadas y documentadas
- **Schema introspection** automÃ¡tica con fallback
- **Estrategias incrementales** configuradas por tabla
- **Error handling** robusto con reintentos
- **44 tablas, 692 columnas** completamente documentadas

### **ğŸ§¹ Lo que Necesita Limpieza (Eliminar/Refactorizar)**
- **CÃ³digo de analytical views** (no funciona, mover a next steps)
- **Cloud Storage** (ya no se usa, limpiar cÃ³digo)  
- **Requirements** dispersos (3 archivos diferentes)
- **Imports** rotos por archivos movidos

## ğŸ“‚ Estructura Actual Limpia

```
src/
â”œâ”€â”€ main_streaming.py              # âœ… Pipeline principal (CORE)
â”œâ”€â”€ main_tables_not_created.py     # ğŸ”§ Troubleshooting (mantener)
â”œâ”€â”€ etl/
â”‚   â””â”€â”€ streaming_extractor.py     # âœ… ExtracciÃ³n optimizada (CORE)
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ connector.py               # âœ… Conexiones MySQL + schema (CORE)
â”‚   â””â”€â”€ secret_manager.py          # âœ… Google Secret Manager (CORE)
â”œâ”€â”€ cloud/
â”‚   â”œâ”€â”€ bigquery.py               # ğŸ§¹ LIMPIAR - Remover analytical views
â”‚   â””â”€â”€ storage.py                # âŒ OBSOLETO - Eliminar (no se usa)
â””â”€â”€ utils/
    â”œâ”€â”€ config.py                 # âœ… Configuraciones (CORE)
    â”œâ”€â”€ schema_mapper.py          # âœ… MySQL â†’ BigQuery mapping (CORE)
    â”œâ”€â”€ mysql_structure_generator.py # âœ… Auto-documentaciÃ³n (CORE)
    â””â”€â”€ mysql_relationship_analyzer.py # ğŸ”§ AnÃ¡lisis FK (herramienta)
```

## ğŸ¯ Casos de Uso del Sistema

### **1. ETL Incremental Diario (Uso Principal)**
```bash
# Proceso estÃ¡ndar - Ãºltimos 3 dÃ­as
python src/main_streaming.py

# FunciÃ³n Python
from src.main_streaming import run_local_streaming
run_local_streaming()
```

### **2. Catch-up Semanal/Mensual** 
```bash
# Reprocesar Ãºltima semana
python src/main_streaming.py --lookback_days=7

# Reproceso mensual
python src/main_streaming.py --lookback_days=30
```

### **3. Full Refresh Emergency**
```bash
# Recargar todo desde cero
python src/main_streaming.py --force_full_refresh=true
```

### **4. Cloud Functions (ProducciÃ³n)**
```bash
# Deploy optimizado
./deploy.sh

# HTTP trigger con parÃ¡metros
curl -X POST https://FUNCTION_URL -d '{"lookback_days": 10}'

# Scheduled trigger (automÃ¡tico)
./setup_scheduler.sh
```

### **5. AnÃ¡lisis y DocumentaciÃ³n**
```bash
# Auto-generar documentaciÃ³n MySQL
python src/utils/mysql_structure_generator.py

# Analizar relaciones FK
python src/utils/mysql_relationship_analyzer.py

# Validar schema mappings
python src/utils/schema_mapper.py
```

## ğŸš§ Tareas Pendientes (Por Prioridad)

### **ğŸ”¥ CRÃTICO - Limpieza Inmediata**

#### **1. Eliminar CÃ³digo de Analytical Views**
**Problema**: Las views en `bigquery.py` lÃ­neas 88-180 no funcionan y causan errores
```python
# ELIMINAR ESTAS LÃNEAS de src/cloud/bigquery.py:
def create_analytical_views(self):  # Lines 88-180
    """Create analytical views based on the existing SQL logic"""
    # TODO: Este cÃ³digo no funciona - mover a next steps
```

**AcciÃ³n**: 
- Remover mÃ©todo `create_analytical_views()` completo
- Remover llamada en `main_streaming.py` lÃ­nea 31
- Mover lÃ³gica a secciÃ³n "Next Steps"

#### **2. Eliminar Cloud Storage Obsoleto**
**Problema**: `src/cloud/storage.py` ya no se usa (streaming directo)
```python
# ARCHIVO COMPLETO OBSOLETO: src/cloud/storage.py
# El nuevo ETL va directo MySQL â†’ BigQuery
```

**AcciÃ³n**:
- Mover `src/cloud/storage.py` a `backup/`
- Verificar que no haya imports rotos

#### **3. Consolidar Requirements**
**Problema**: 3 archivos diferentes confunden las dependencias
```bash
requirements.txt           # Principal 
requirements-cloud.txt     # Cloud Functions
requirements-minimal.txt   # MÃ­nimo
```

**AcciÃ³n**:
- Consolidar en `requirements.txt` Ãºnico
- Eliminar dependencias no utilizadas
- Validar que todo funciona

### **âš¡ ALTO - OptimizaciÃ³n de CÃ³digo**

#### **4. Arreglar Imports Rotos**
**Problema**: Los archivos movidos a backup pueden causar ImportError

**AcciÃ³n**:
- Ejecutar `python src/main_streaming.py` para detectar imports rotos
- Arreglar referencias faltantes
- Validar que todos los mÃ³dulos cargan correctamente

#### **5. Refactorizar BigQuery Manager**
**Problema**: MÃ©todos mezclados (streaming + obsoletos)

**AcciÃ³n**:
- Mantener solo mÃ©todos streaming: `load_dataframe_to_table()`, `create_dataset_if_not_exists()`
- Eliminar mÃ©todos obsoletos: `create_external_table()`, `create_all_external_tables()`
- Simplificar clase para uso streaming Ãºnicamente

### **ğŸ“Š MEDIO - Mejoras Funcionales**

#### **6. Implementar Estrategias Incrementales Avanzadas**
**Objetivo**: Usar las 86 relaciones FK descubiertas

**ImplementaciÃ³n**:
```python
# Ejemplo: factcabecera cluster incremental
factcabecera_strategy = {
    'parent': 'factcabecera',
    'children': ['factlineas', 'factpagos', 'factcoberturas'],
    'join_column': 'IDComprobante',
    'watermark': 'emision'
}
```

#### **7. Optimizar Performance por Tabla**
**Basado en volumen de datos**:
- **33M+ filas** (asientos_detalle): Chunks 50k, cada 4h
- **13M+ filas** (factlineas): Chunks 100k, cada 6h  
- **<1M filas** (master data): Chunks 200k, diario

#### **8. Mejorar Error Handling**
- Logging estructurado (no solo prints)
- Notificaciones de errores crÃ­ticos
- Recovery automÃ¡tico en fallos de chunks

### **ğŸš€ LARGO PLAZO - Nuevas CaracterÃ­sticas**

#### **9. Analytical Views (Next Steps)**
**Objetivo**: Crear vistas analÃ­ticas que SÃ funcionen
```sql
-- Ejemplos de vistas necesarias:
CREATE VIEW v_ventas_consolidadas AS ...
CREATE VIEW v_inventario_actual AS ...  
CREATE VIEW v_prescripciones_tracking AS ...
```

#### **10. Data Quality & Monitoring**
- ValidaciÃ³n automÃ¡tica de datos
- MÃ©tricas de calidad de datos
- Dashboards de monitoreo ETL

#### **11. Parallel Processing**
- Procesamiento paralelo de tablas independientes
- OptimizaciÃ³n de recursos Cloud Functions
- Schedulers diferenciados por criticidad

## ğŸ› ï¸ Plan de ImplementaciÃ³n (PrÃ³ximas 2 Semanas)

### **Semana 1: Limpieza CrÃ­tica**
- **DÃ­a 1-2**: Eliminar analytical views + cloud storage
- **DÃ­a 3-4**: Consolidar requirements + arreglar imports
- **DÃ­a 5**: Validar que ETL streaming funciona 100%

### **Semana 2: Optimizaciones**  
- **DÃ­a 1-2**: Refactorizar BigQuery Manager
- **DÃ­a 3-4**: Implementar estrategias incrementales avanzadas
- **DÃ­a 5**: Testing completo + documentaciÃ³n

## ğŸ“Š MÃ©tricas de Ã‰xito

### **TÃ©cnicas**
- âœ… **ETL streaming**: 0 errores de schema/tipos
- âœ… **Performance**: <45min para full load
- âœ… **Incremental**: <5min para load diario
- âœ… **Reliability**: >99% success rate

### **Operacionales**
- âœ… **Cost**: <$25/mes (actual ~$23/mes)
- âœ… **Data Freshness**: <2 horas lag mÃ¡ximo
- âœ… **Monitoring**: Alertas automÃ¡ticas en fallos

## ğŸ”„ Comando de ValidaciÃ³n

**Para probar que todo funciona despuÃ©s de cada cambio**:
```bash
# Test completo del sistema
python src/main_streaming.py --lookback_days=1

# Debe retornar:
# âœ… Schema introspection working
# âœ… MySQL connections successful  
# âœ… BigQuery load successful
# âœ… All 44 tables processed
# âœ… No import errors
```

## ğŸ“ Support & Questions

**Si algo no funciona despuÃ©s de los cambios**:
1. Check `claude_sessions/SESSION_2025-08-25_CLEANUP.md` 
2. Revisar archivos movidos a `backup/`
3. Validar que `requirements.txt` tiene todas las dependencias
4. Ejecutar test de validaciÃ³n arriba

## ğŸ”„ **Mejoras Futuras - Logging System**

### **ETL Audit & Logging Infrastructure**
1. **Crear schema de auditorÃ­a** `plex_etl_audit` en BigQuery
2. **Tablas de logging**:
   - `etl_execution_log` - Registro de cada ejecuciÃ³n ETL (inicio, fin, status)
   - `table_processing_log` - Log por tabla (filas procesadas, tiempo, errores)  
   - `incremental_watermarks` - Tracking de marcas de agua por tabla
   - `data_quality_metrics` - MÃ©tricas de calidad por tabla/columna
3. **Implementar en StreamingDataExtractor**:
   - Log inicio/fin de cada tabla
   - Capturar mÃ©tricas (filas MySQL vs BigQuery, tiempo procesamiento)
   - Alertas automÃ¡ticas por fallos o discrepancias
4. **Dashboard de monitoreo** con mÃ©tricas ETL en tiempo real

---

**ğŸ¯ Objetivo**: Sistema ETL limpio, optimizado y 100% funcional para anÃ¡lisis farmacÃ©utico  
**ğŸ“… Target**: 2 semanas para completar todas las optimizaciones crÃ­ticas